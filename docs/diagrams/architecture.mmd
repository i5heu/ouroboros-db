classDiagram
    class Cluster {
        -[]Node Nodes
    }

    class Node {
        +NodeID NodeID
        +[]string Addresses
        +NodeCert NodeCert
    }

    %% NodeCert: Node identity certificate payload.
    %% Contents:
    %% - Carries the node public key material (composite keys.PublicKey: KEM + Sign).
    %% - Identifies the issuer CA by hash (IssuerCAHash).
    %%   - There can be multiple AdminCAs and multiple UserCAs.
    %%   - IssuerCAHash allows selecting the expected CA without trial-verifying many roots.
    %% NodeID derivation:
    %% - NodeID is NOT a free-form name.
    %% - NodeID is derived ONLY from the node public key material:
    %%   NodeID = SHA-256(NodePubKey).
    %% - AdminCA/UserCA signatures authorize the node but do not change its NodeID.
    %% Signature scope (what is signed):
    %% - The CA signature MUST be over a canonical serialization of the ENTIRE NodeCert
    %%   structure (including IssuerCAHash and any future metadata like expiry/constraints).
    %% - Sign/Verify MUST use cryptographic domain separation to prevent type confusion
    %%   between different signed payload types.
    %% - Required form:
    %%   CA_Signature = Sign(CTX_NODE_ADMISSION_V1 || CanonicalSerialize(NodeCert))
    %% - This follows the "what you see is what was signed" rule and prevents mutable fields.
    %% Identity model:
    %% - There is NO name/CN/SAN-based identity. The only stable identity is NodeID derived
    %%   from NodePubKey().
    %% - Any presented NodeID must be treated as informational unless recomputed from NodePubKey().
    %% Security (proof of possession / binding):
    %% - The peer is ONLY authenticated if the QUIC/TLS session proves possession of the
    %%   private key corresponding to NodePubKey().publicSign.
    %% - This prevents replay/impersonation if an attacker obtains a valid NodeCert + CA signature.
    class NodeCert {
        +NodePubKey() keys.PublicKey
        +IssuerCAHash() CaHash.Hash
        +NodeID() keys.NodeID
    }

    %% TrustScope: Authentication scope of a connected peer.
    %% - ScopeAdmin: AdminCA-authorized node.
    %%   - May perform system/cluster actions.
    %%   - May request any data (subject to cluster policy), not tied to a specific user.
    %% - ScopeUser: UserCA-authorized node.
    %%   - Must be sandboxed; never allow system/cluster actions.
    %%   - May request ONLY data belonging to the user identity represented by the issuing
    %%     UserCA (peerCert.IssuerCAHash()) while the node is connected and not revoked.
    %%   - No per-request user signature is required because the node identity is already
    %%     authenticated (PoP) and authorized (CA admission); the authorization boundary is
    %%     enforced by scoping all requests to that issuing UserCAHash.
    class TrustScope {
        <<Enumeration>>
        ScopeAdmin
        ScopeUser
    }

    class ClusterController {
    }

    class ClusterMonitor {
        +MonitorNodeHealth()
        +CollectClusterLogs()
        +GetDataState()
        +CollectNodeStats()
        +GetNodeStats(nodeID string) (NodeStats, error)
    }

    %% ClusterLog: Cluster-wide log aggregation.
    %% Purpose:
    %% - Single place to collect operational logs/events from every Node.
    %% - Makes it easy to debug replication, routing, and failures without SSH-ing into nodes.
    %% - Enables cluster-level timelines ("what happened across the system at time T?").
    %%
    %% What it contains:
    %% - Timestamped LogEntry records tagged with NodeID + Level and optional structured fields.
    %%
    %% What it is NOT:
    %% - Not the long-term analytics system; it is a conceptual component for centralized visibility.
    class ClusterLog {
        +New(logger *slog.Logger, carrier Carrier, selfID NodeID) *ClusterLog
        +Stop()
        +Log(ctx context.Context, level LogLevel, msg string, fields map~string, string~)
        +Info(ctx context.Context, msg string, fields map~string, string~)
        +Warn(ctx context.Context, msg string, fields map~string, string~)
        +Debug(ctx context.Context, msg string, fields map~string, string~)
        +Err(ctx context.Context, msg string, fields map~string, string~)
        +Tail(limit int) []LogEntry
        +Query(nodeID NodeID, since time.Time) []LogEntry
        +QueryAll(since time.Time) []LogEntry
        +QueryByLevel(level LogLevel, since time.Time) []LogEntry
        +SubscribeLog(ctx context.Context, sourceNodeID NodeID, subscriberNodeID NodeID)
        +SubscribeLogAll(ctx context.Context, subscriberNodeID NodeID)
        +UnsubscribeLog(ctx context.Context, sourceNodeID NodeID, subscriberNodeID NodeID)
        +UnsubscribeLogAll(ctx context.Context, subscriberNodeID NodeID)
        +SendLog(ctx context.Context, targetNodeID NodeID, sourceNodeID NodeID, since time.Time) error
    }

    class LogEntry {
        +time.Time Timestamp
        +keys.NodeID NodeID
        +LogLevel Level
        +string Message
        +map~string, string~ Fields
    }

    class LogLevel {
        <<Enumeration>>
        Debug
        Info
        Warn
        Error
    }

    %% DataState: Cluster-wide data placement + status view.
    %% Purpose:
    %% - Answer "which node has which data" and "what is its current state" at a glance.
    %% - Provides an operational index for replication monitoring, rebalancing, repair, and offline sync.
    %%
    %% Scope of "Data": the objects modeled in Logical_Hierarchy + Block_Storage_Modern:
    %% - Vertex (logical DAG nodes)
    %% - SealedChunk (encrypted chunk payloads)
    %% - KeyEntry (access-control entries)
    %% - Block and BlockSlice (physical archive and shards)
    %%
    %% Status examples:
    %% - Present/Missing (inventory)
    %% - Syncing (in-progress replication)
    %% - PendingDelete (DeletionWAL/GC lifecycle)
    %% - Corrupt (integrity mismatch / failed reconstruction)
    class DataState {
        +GetNodesForVertex(vertexHash hash.Hash) ([]NodeDataStatus, error)
        +GetNodesForSealedChunk(chunkHash hash.Hash) ([]NodeDataStatus, error)
        +GetNodesForBlock(blockHash hash.Hash) ([]NodeDataStatus, error)
        +GetNodesForBlockSlice(sliceHash hash.Hash) ([]NodeDataStatus, error)
        +GetNodeInventory(nodeID string) ([]NodeDataStatus, error)
    }

    class NodeDataStatus {
        +string NodeID
        +hash.Hash DataHash
        +DataStatus Status
        +string Detail
    }

    class DataStatus {
        <<Enumeration>>
        Present
        Missing
        Syncing
        PendingDelete
        Corrupt
    }

    %% NodeStats: Per-node storage statistics (fast "at a glance" view).
    %% Purpose:
    %% - Quick capacity/health signal: how much the node is storing across major object types.
    %% - Supports dashboards and placement decisions (e.g., rebalancer choosing less-loaded nodes).
    %% - Helps identify skew (too many slices/blocks on one node) and replication gaps.
    %%
    %% Notes:
    %% - Counts cover the same "Data" scope as DataState (Logical_Hierarchy + Block_Storage_Modern).
    %% - "Chunks" at rest are represented as SealedChunks (encrypted payloads).
    class NodeStats {
        +string NodeID
        +int64 Updated
        +uint64 VertexCount
        +uint64 BlockCount
        +uint64 BlockSliceCount
        +uint64 SealedChunkCount
        +uint64 KeyEntryCount
    }

    class NodeAvailabilityTracker {
        +TrackAvailability()
    }

    class Carrier {
        +GetNodes() []Node
        +Broadcast(message Message) (success []Node, error)
        +SendMessageToNode(nodeID NodeID, message Message) error
        
        +JoinCluster(clusterNode Node, nodeCert NodeCert) error
        +LeaveCluster(clusterNode Node) error
    }

    %% AdminCA: Cluster admin certificate authority (one trust root).
    %% Trust model:
    %% - The cluster may trust MULTIPLE AdminCAs (multi-root). Each AdminCA represents
    %%   exactly one Admin signing public key + its identifier.
    %% - AdminCA is verification-only: signing/issuance happens off-device/out-of-band.
    %% What it verifies:
    %% - A "node certificate" is the peer-presented NodeCert plus a detached CA signature.
    %% - VerifyNodeCert checks the CA signature is valid under this Admin pubkey over the
    %%   domain-separated payload:
    %%   SignInput = CTX_NODE_ADMISSION_V1 || CanonicalSerialize(NodeCert)
    %%   (not over a name or string identifier).
    %% - On success, the returned NodeID MUST be computed from the NodeCert itself:
    %%   NodeID = SHA-256(NodeCert.NodePubKey).
    %% - This verifies issuance/authorization of the NodeCert, NOT proof-of-possession.
    %% Proof of possession (PoP):
    %% - PoP is provided by the QUIC/TLS handshake: the peer must prove possession of the
    %%   private signing key corresponding to NodeCert.NodePubKey().publicSign.
    %% Hash semantics:
    %% - Hash() is the SHA-256 identifier of the Admin public key.
    %% - Nodes can exchange/compare AdminCAHash values to agree on which Admin root is trusted
    %%   without transmitting full key material.
    %% Enforcement:
    %% - A peer is considered an "admin-authorized node" only if (1) VerifyNodeCert succeeds
    %%   under at least one trusted AdminCA and (2) the NodeID is not revoked by CarrierAuth.
    class AdminCA {
        +PubKey() sign.PublicKey
        +Hash() CaHash.Hash
        +VerifyNodeCert(nodeCert NodeCert, caSignature []byte) (nodeID NodeID, error)
    }

    %% UserCA: User certificate authority (one trust root).
    %% Purpose:
    %% - Represents a user identity root for user-scoped node admission.
    %% Identification:
    %% - Hash() is the SHA-256 identifier of the UserCA public key (UserCAHash).
    %% - Requesting nodes can send only UserCAHash to reference the correct UserCA.
    %% Node admission:
    %% - VerifyNodeCert validates user-signed node certificates.
    %% - The signature is always a cryptographic signature over the domain-separated NodeCert
    %%   payload (never a name):
    %%   CTX_NODE_ADMISSION_V1 || CanonicalSerialize(NodeCert).
    %% - On success, the returned NodeID MUST be computed from the NodeCert itself:
    %%   NodeID = SHA-256(NodeCert.NodePubKey).
    %% - Nodes admitted under a UserCA are "user-scoped" and must be restricted to data
    %%   belonging to that UserCA (not full cluster authority).
    %% Proof of possession (PoP):
    %% - As with AdminCA, PoP is provided by the QUIC/TLS handshake using the NodeCert signing key.
    class UserCA {
        +PubKey() sign.PublicKey
        +Hash() CaHash.Hash
        +VerifyNodeCert(nodeCert NodeCert, caSignature []byte) (nodeID NodeID, error)
    }

    %% CarrierAuth (pkg): Carrier-side authentication + trust-root management.
    %% Inputs:
    %% - Carrier extracts identity material from the QUIC handshake:
    %%   - peerCert: NodeCert
    %%   - caSignature: detached CA signature over CTX_NODE_ADMISSION_V1 || canonical(NodeCert)
    %%   - tlsPeerPubKey: the QUIC/TLS authenticated peer signing public key
    %%     (the key the peer proved possession of during the TLS handshake)
    %% Decision:
    %% - VerifyPeerCert attempts to authenticate the peer as either:
    %%   - admin-authorized node: NodeCert verifies under a trusted AdminCA, OR
    %%   - user-scoped node: NodeCert verifies under a trusted UserCA.
    %% - On success it returns the authenticated NodeID AND the TrustScope.
    %% - On failure it returns error and the connection MUST be rejected.
    %% Proof of possession (PoP) requirement:
    %% - CarrierAuth MUST reject unless tlsPeerPubKey matches peerCert.NodePubKey().publicSign.
    %% - This binds the presented NodeCert to the transport session and prevents replay.
    %% Namespace collision requirement:
    %% - Because NodeID is CA-independent, callers MUST NOT use NodeID alone to grant
    %%   system privileges.
    %% - Callers MUST enforce authorization using TrustScope:
    %%   - ScopeAdmin => eligible for system-level actions and cluster-wide data requests
    %%   - ScopeUser  => sandboxed; never allow system-level actions
    %%     - may request ONLY data belonging to the issuing UserCAHash of the authenticated
    %%       NodeCert (peerCert.IssuerCAHash())
    %% Trust-root management:
    %% - Add/RemoveAdminPubKey updates the trusted AdminCA set (keyed by AdminCAHash).
    %% - Add/RemoveUserPubKey updates the trusted UserCA set (keyed by UserCAHash).
    %% Revocation:
    %% - RevokeNode denies a NodeID even if it presents a valid certificate.
    %% - Revocation applies to both admin-authorized and user-scoped nodes.
    %% - RevokeAdminCA / RevokeUserCA disables a CA by hash (stronger than Remove*; intended
    %%   to prevent re-adding the same root without an explicit un-revoke policy).
    %% Authorization boundary (important):
    %% - Authentication answers "who is the peer node?" (NodeID + which CA validated it).
    %% - Authorization answers "what may it do?" and must be enforced by higher-level
    %%   components (e.g., routing/ACL), especially for user-scoped nodes.
    class CarrierAuth {
        +VerifyPeerCert(peerCert NodeCert, caSignature []byte, tlsPeerPubKey sign.PublicKey) (nodeID NodeID, scope TrustScope, error)
        +AddAdminPubKey(pubKey sign.PublicKey) error
        +RemoveAdminPubKey(pubKeyHash CaHash.Hash) error
        +RevokeAdminCA(adminCAHash CaHash.Hash) error
        +AddUserPubKey(pubKey sign.PublicKey) error
        +RemoveUserPubKey(pubKeyHash CaHash.Hash) error
        +RevokeUserCA(userCAHash CaHash.Hash) error
        +RevokeNode(nodeID NodeID) error
    }

    class BootStrapper {
        +BootstrapNode(node Node) error
    }

    Carrier "1" *-- "1" BootStrapper : initializes
    Carrier "1" *-- "1" CarrierAuth : authenticatesVia
    CarrierAuth ..> "1..*" AdminCA : verifiesPeerCertWith
    CarrierAuth ..> "0..*" UserCA : verifiesPeerCertWith
    AdminCA ..> Node : validatesAdminSignedNodeCertFor
    UserCA ..> Node : validatesUserSignedNodeCertFor

    class Message  {
        +MessageType Type
        +[]byte Payload
    }
    Carrier "1" o-- "*" Message : sends/receives

    class MessageType {
        <<Enumeration>>
        BlockSliceRequest
        BlockSliceResponse
        ChunkMetaRequest
        VertexMetaRequest
        %% Heartbeat is also used for monitoring information
        Heartbeat
        NodeJoinRequest
        NodeLeaveNotification
        UserAuthDecision
        NewNodeAnnouncement
        KeyEntryRequest
        KeyEntryResponse
        BlockSyncRequest
        LogPush
        LogSendResponse
    }
    Message "1" o-- "1" MessageType : has type


    %% DataRouter: Routes data operations across the cluster.
    %% Coordinates with CAS for content operations and handles
    %% distribution of blocks/slices to appropriate nodes.
    class DataRouter {
        +StoreVertex(vertex Vertex) (hash.Hash, error)
        +RetrieveVertex(hash.Hash) (Vertex, error)
        +DeleteVertex(hash.Hash) error
        +DistributeBlockSlices(block Block) error
        +RetrieveBlock(hash.Hash) (Block, error)
    }

    %% BlockDistributionTracker: Tracks block distribution and confirmations.
    %% Responsible for tracking slice confirmations, pending distributions,
    %% and providing metadata for offline node sync.
    class BlockDistributionTracker {
        +StartDistribution(block Block, walKeys [][]byte) (*BlockDistributionRecord, error)
        +RecordSliceConfirmation(blockHash hash.Hash, sliceHash hash.Hash, nodeID string) (bool, error)
        +GetDistributionState(blockHash hash.Hash) (*BlockDistributionRecord, error)
        +GetPendingDistributions() ([]*BlockDistributionRecord, error)
        +MarkDistributed(blockHash hash.Hash) error
        +MarkFailed(blockHash hash.Hash, reason string) error
        +GetDistributedBlocksSince(since int64) ([]hash.Hash, error)
        +GetBlockMetadata(blockHash hash.Hash) (*BlockMetadata, error)
    }

    %% CAS: Content Addressable Storage - the main management layer.
    %% Provides high-level API for content operations, coordinating
    %% encryption, WAL buffering, block storage, and access control.
    class CAS {
        %% Content operations (high-level API)
        +StoreContent(content []byte, parentHash hash.Hash) (Vertex, error)
        +GetContent(vertexHash hash.Hash) ([]byte, error)
        +DeleteContent(vertexHash hash.Hash) error
        
        %% Vertex operations
        +GetVertex(hash.Hash) (Vertex, error)
        +ListChildren(parentHash hash.Hash) ([]Vertex, error)
        
        %% Internal dependencies
        -DistributedWAL wal
        -BlockStore blockStore
        -EncryptionService encryptor
    }

    %% BlockStore: Low-level Block and BlockSlice persistence.
    %% Handles physical storage and retrieval of blocks and their shards.
    class BlockStore {
        +StoreBlock(Block) error
        +GetBlock(hash.Hash) (Block, error)
        +DeleteBlock(hash.Hash) error
        +StoreBlockSlice(BlockSlice) error
        +GetBlockSlice(hash.Hash) (BlockSlice, error)
        +ListBlockSlices(blockHash hash.Hash) ([]BlockSlice, error)

        %% Region-based retrieval for efficient partial reads
        +GetSealedChunkByRegion(blockHash hash.Hash, region ChunkRegion) (SealedChunk, error)
        +GetVertexByRegion(blockHash hash.Hash, region VertexRegion) (Vertex, error)
    }

    %% EncryptionService: Handles encryption/decryption of chunks.
    %% Manages the Chunk <-> SealedChunk transformation.
    class EncryptionService {
        +SealChunk(Chunk, pubKeys [][]byte) (SealedChunk, []KeyEntry, error)
        +UnsealChunk(SealedChunk, KeyEntry, privKey []byte) (Chunk, error)
        +GenerateKeyEntry(chunkHash hash.Hash, pubKey []byte, aesKey []byte) (KeyEntry, error)
    }

    class DeletionWAL {
        +LogDeletion(hash.Hash) error
        +ProcessDeletions() error
    }

    class DistributedIndex 

    class HashToNode {
        +GetNodeForHash(hash.Hash) Node
    }

    class KeyToHashAndNode {
        +GetHashAndNodeForKey(string) (hash.Hash, Node, error)
    }

    class DataReBalancer {
        +BalanceData()
    }

    class ReplicationMonitoring {
        +MonitorReplications()
    }

    class SyncIndexTree {
        +Sync()
    }

    class BackupManager {
        +BackupData()
    }

    Cluster "1" *-- "*" Node : contains
    Node "1" o-- "*" ClusterController : listensOn
    ClusterController "1" *-- "1" Carrier : communicatesVia
    Node "1" o-- "1" CAS : manages content
    Node "1" *-- "1" BlockStore : persists blocks
    DataRouter "1" *-- "1" ClusterController : interacts with
    CAS "1" *-- "1" DataRouter : coordinates distribution via
    DataRouter "1" o-- "1" BlockDistributionTracker : initiates distribution via
    ClusterController "1" o-- "1" BlockDistributionTracker : queries for offline node sync
    BlockDistributionTracker "1" *-- "*" Block : tracks distribution for
    CAS "1" *-- "1" BlockStore : stores blocks via
    CAS "1" *-- "1" EncryptionService : encrypts/decrypts via
    CAS "1" *-- "1" DistributedWAL : buffers writes via
    ClusterController "1" *-- "1" DistributedIndex : LooksUps
    DistributedIndex "1" *-- "1" HashToNode : used for mapping
    DistributedIndex "1" *-- "1" KeyToHashAndNode : lookups for keys
    ClusterController "1" *-- "1" DataReBalancer : manages
    DataReBalancer "1" *-- "1" ReplicationMonitoring : utilizes
    ClusterController "1" *-- "1" ClusterMonitor : monitors
    Node "1" *-- "1" BackupManager : manages backups
    ClusterMonitor "1" *-- "1" NodeAvailabilityTracker : utilizes
    ClusterMonitor "1" *-- "1" ClusterLog : aggregates
    ClusterMonitor "1" *-- "1" DataState : tracks
    ClusterMonitor "1" o-- "*" NodeStats : collects
    DataReBalancer "1" *-- "1" SyncIndexTree : utilizes
    Node "1" *-- "1" DeletionWAL : logs deletions

    %% Nodes emit logs into the cluster-wide log.
    Node ..> ClusterLog : emits logs to

    %% DataState maps data to nodes with status.
    %% Tracks objects from Logical_Hierarchy + Block_Storage_Modern:
    %% Vertex, SealedChunk, Block, BlockSlice, KeyEntry.
    DataState "1" o-- "*" Node : maps data to nodes

    %% NodeStats are associated with nodes.
    Node "1" o-- "*" NodeStats : reports

    %% (Diagram simplification) LogEntry/LogLevel are internal to ClusterLog.


    namespace IndexModel {
        class Index {
            -LocalIndexStore store
        }
        class parentChildIndex {
            - map<hash.Hash, []hash.Hash> ParentToChildren
            - map<hash.Hash, hash.Hash> ChildToParent
        }
        class VersionIndex {
            - map<hash.Hash, []hash.Hash> VersionVectorHeads
        }
        class KeyToHashIndex {
            - map<string, hash.Hash> KeyToHash
        }
    }

    Node "1" o-- "1" Index : indexes relations and metadata
    Index "1" o-- "1" parentChildIndex : manages
    Index "1" o-- "1" VersionIndex : manages

    namespace Logical_Hierarchy {
        %% Vertex (formerly Blob): The logical node in the DAG.
        %% stored UNENCRYPTED in the VertexSection of the Block.
        class Vertex {
            +hash.Hash Hash
            +hash.Hash Parent
            +int64 Created
            -[]hash.Hash ChunkHashes
            +GetContent() []byte
        }

        %% Chunk: The cleartext content.
        %% Only exists temporarily in memory during processing/decryption.
        class Chunk {
            +hash.Hash Hash
            +int Size
            -[]byte content
            +GetContent() []byte
        }
    }

    namespace Block_Storage_Modern {
        %% DistributedWAL: Intake buffer.
        %% Aggregates items until Block size (e.g., 16MB) is reached.
        class DistributedWAL {
            +AppendChunk(SealedChunk)
            +AppendVertex(Vertex)
            +SealBlock() Block
            -[]SealedChunk chunkBuffer
            -[]Vertex vertexBuffer
        }

        %% SealedChunk: The encrypted payload.
        %% Now includes SealedHash for integrity checking of the encrypted data 
        %% without needing decryption keys.
        class SealedChunk {
            +hash.Hash ChunkHash
            +hash.Hash SealedHash
            +[]byte EncryptedContent
            +[]byte Nonce
            +int OriginalSize
        }

        %% KeyEntry: The Access Control unit.
        %% Explicitly links the User (PubKey) to the Content (ChunkHash).
        class KeyEntry {
            +hash.Hash ChunkHash
            +hash.Hash PubKeyHash
            +[]byte EncapsulatedAESKey
        }

        %% The Indices that allow for byte range like requests
        %% This prevents that we need to decode the whole Block to get a single Chunk/Vertex.
        class ChunkRegion {
            +hash.Hash ChunkHash
            +uint32 Offset
            +uint32 Length
        }
        class VertexRegion {
            +hash.Hash VertexHash
            +uint32 Offset
            +uint32 Length
        }

        %% BlockHeader: Global block settings.
        class BlockHeader {
            +uint8 Version
            +int64 Created
            +uint8 RSDataSlices
            +uint8 RSParitySlices
            +uint32 ChunkCount
            +uint32 VertexCount
            +uint32 TotalSize
        }

        %% Block: The Central Archive.
        class Block {
            +hash.Hash Hash
            +BlockHeader Header
            +[]byte DataSection
            +[]byte VertexSection
            +map~Hash, []KeyEntry~ KeyRegistry
        }

        %% BlockSlice: The physical shard.
        class BlockSlice {
            +hash.Hash Hash
            +hash.Hash BlockHash
            +uint8 RSSliceIndex
            +uint8 RSDataSlices
            +uint8 RSParitySlices
            +[]byte Payload
        }
    }

    %% ==========================================
    %% 1. LOGICAL RELATIONSHIPS
    %% ==========================================
    Vertex "1" ..> "*" Chunk : references (via ChunkHash)

    %% ==========================================
    %% 2. PIPELINE & TRANSFORMATION
    %% ==========================================
    Chunk ..> SealedChunk : encrypts to
    SealedChunk --* DistributedWAL : buffered in
    Vertex --* DistributedWAL : buffered in
    DistributedWAL ..> Block : produces (SealBlock)

    %% ==========================================
    %% 3. BLOCK COMPOSITION
    %% ==========================================
    %% Structure
    Block "1" *-- "1" BlockHeader : has
    Block "1" *-- "*" ChunkRegion : indexes
    Block "1" *-- "*" VertexRegion : indexes
    
    %% Payloads
    Block "1" *-- "*" SealedChunk : contains (in DataSection)
    Block "1" *-- "*" Vertex : contains (in VertexSection)
    
    %% Registries
    Block "1" *-- "*" KeyEntry : registry (Access Control)

    %% ==========================================
    %% 4. PHYSICAL STORAGE
    %% ==========================================
    BlockSlice ..> Block : shards/reconstructs
    BlockStore "1" o-- "*" Block : persists
    BlockStore "1" o-- "*" BlockSlice : persists
    
    %% ==========================================
    %% 5. FUNCTIONAL LINKS
    %% ==========================================
    ChunkRegion ..> SealedChunk : locates bytes of
    VertexRegion ..> Vertex : locates bytes of
    KeyEntry ..> SealedChunk : unlocks (via ChunkHash)
    EncryptionService ..> SealedChunk : produces
    EncryptionService ..> KeyEntry : produces